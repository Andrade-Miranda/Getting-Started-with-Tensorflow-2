{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Saving and loading model weights](#coding_tutorial_1)\n",
    " #### [2. Model saving criteria](#coding_tutorial_2)\n",
    " #### [3. Saving the entire model](#coding_tutorial_3)\n",
    " #### [4. Loading pre-trained Keras models](#coding_tutorial_4)\n",
    " #### [5. Tensorflow Hub modules](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Saving and loading model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inspect CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of, in total, 60000 color images, each with one of 10 labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. For an introduction and a download, see [this link](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the CIFAR-10 dataset and rescale the pixel values\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 10 CIFAR-10 images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 15, figsize=(10, 1))\n",
    "for i in range(15):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduce two useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce function to test model accuracy\n",
    "\n",
    "def get_test_accuracy(model, x_test, y_test):\n",
    "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "    print('accuracy: {acc:0.3f}'.format(acc=test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce function that creates a new instance of a simple CNN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "def get_new_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), \n",
    "               activation='relu', name='conv_1'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),\n",
    "        MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_3'),\n",
    "        MaxPooling2D(pool_size=(4, 4), name='pool_2'),\n",
    "        Flatten(name='flatten'),\n",
    "        Dense(units=32, activation='relu', name='dense_1'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(units=10, activation='softmax', name='dense_2')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create simple convolutional neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the model and show model summary\n",
    "\n",
    "model = get_new_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test accuracy of the untrained model, around 10% (random)\n",
    "\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object\n",
    "path ='model_checkpoints/checkpoints' \n",
    "checkpoint = ModelCheckpoint(filepath=path, frequency='epoch', save_weights_only=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit model, with simple checkpoint which saves (and overwrites) model weights every epoch\n",
    "\n",
    "model.fit(x_train,y_train,epochs=20, batch_size=64, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "\n",
    "!dir model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of the trained model\n",
    "\n",
    "get_test_accuracy(model, x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new model, load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new instance of the (initialised) model, accuracy around 10% again\n",
    "\n",
    "model2 = get_new_model()\n",
    "get_test_accuracy(model2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights -- accuracy is the same as the trained model\n",
    "model2.load_weights(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_test_accuracy(model2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "! rm -r model_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Model saving criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create more customised checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object with epoch and batch details\n",
    "# Creating a model which saves weights every 5000 training training points\n",
    "\n",
    "checkpoint_5000_path = 'checkpoint_5000/checkpoint_{epoch:02d}_{batch:04d}'\n",
    "\n",
    "model = get_new_model()\n",
    "checkpoint_5000 = ModelCheckpoint(filepath=checkpoint_5000_path, verbose=True, save_weights_only=True,\n",
    "                                  save_freq=5000)\n",
    "model.fit(x_train, y_train, batch_size=10, validation_data=(x_test,y_test), epochs=3, verbose= True, callbacks=[checkpoint_5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model with checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with model saving criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tiny training and test set -- will overfit!\n",
    "\n",
    "x_train = x_train[:100]\n",
    "y_train = y_train[:100]\n",
    "x_test = x_test[:100]\n",
    "y_test = y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of untrained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object which monitors the validation accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and save only the weights with the highest validation accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing curves\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(y=['accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the checkpoint directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the saved weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model_checkpoints_5000 model_checkpoints_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Saving the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create checkpoint that saves whole model, not just weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object\n",
    "checkpoint_path = 'model_checkpoints'\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_path, save_weights_only=False,\n",
    "save_freq = 'epoch',\n",
    "verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and fit model with checkpoint\n",
    "\n",
    "model = get_new_model()\n",
    "model.fit(x_train, y_train, epochs=5, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect what the checkpoint has created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "!dir model_checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dir model_checkpoints\\assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter variables directory\n",
    "!dir model_checkpoints\\variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the model's test accuracy\n",
    "get_test_accuracy(model, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload model from scratch\n",
    "newModel = load_model(checkpoint_path)\n",
    "get_test_accuracy(newModel, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the .h5 format to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in .h5 format\n",
    "newModel.save('myModel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect .h5 file\n",
    "!dir myModel.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "del newModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload model from scratch\n",
    "newModel = load_model('myModel.h5')\n",
    "get_test_accuracy(newModel, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model_checkpoints\n",
    "! rm my_model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Loading pre-trained Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and build Keras ResNet50 model\n",
    "\n",
    "Today we'll be using the ResNet50 model designed by a team at Microsoft Research, available through Keras applications. Please see the description on the [Keras applications page](https://keras.io/applications/#resnet) for details. If you continue using it, please cite it properly! The paper it comes from is:\n",
    "\n",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. \"Deep Residual Learning for Image Recognition\", 2015.\n",
    "\n",
    "This model takes a long time to download on the Coursera platform, so it is pre-downloaded in your workspace and saved in Keras HDF5 format. If you want to import it on your personal machine, use the following code:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "model = ResNet50(weights='imagenet')\n",
    "```\n",
    "\n",
    "In this coding tutorial, you will instead load the model directly from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build Keras ResNet50 model\n",
    "model = ResNet50(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and preprocess 3 sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3 sample ImageNet images\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "cat1 = load_img('data/cat1.jpg', target_size=(224, 224))\n",
    "bird1 = load_img('data/bird1.jpg', target_size=(224, 224))\n",
    "bird2 = load_img('data/bird2.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ResNet50 model to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function: presents top 5 predictions and probabilities\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_5_predictions(img):\n",
    "    x = img_to_array(img)[np.newaxis, ...]\n",
    "    x = preprocess_input(x)\n",
    "    preds = decode_predictions(model.predict(x), top=5)\n",
    "    top_preds = pd.DataFrame(columns=['prediction', 'probability'],\n",
    "                             index=np.arange(5)+1)\n",
    "    for i in range(5):\n",
    "        top_preds.loc[i+1, 'prediction'] = preds[0][i][1]\n",
    "        top_preds.loc[i+1, 'probability'] = preds[0][i][2] \n",
    "    return top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 1: bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "\n",
    "get_top_5_predictions(bird1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 2: bird2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "bird2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "\n",
    "get_top_5_predictions(bird2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 3: cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "cat1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "\n",
    "get_top_5_predictions(cat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Tensorflow Hub modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and build Tensorflow Hub MobileNet v1 model\n",
    "\n",
    "Today we'll be using Google's MobileNet v1 model, available on Tensorflow Hub. Please see the description on the [Tensorflow Hub page](https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4) for details on it's architecture, how it's trained, and the reference. If you continue using it, please cite it properly! The paper it comes from is:\n",
    "\n",
    "Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam: \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\", 2017.\n",
    "\n",
    "This model takes a long time to download on the Coursera platform, so it is pre-downloaded in your workspace and saved in Tensorflow SavedModel format. If you want to import it on your personal machine, use the following code:\n",
    "\n",
    "```python\n",
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\n",
    "model = Sequential([hub.KerasLayer(module_url)])\n",
    "model.build(input_shape=[None, 160, 160, 3])\n",
    "```\n",
    "\n",
    "In this coding tutorial, you will instead load the model directly from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Google's Mobilenet v1 model\n",
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\n",
    "model = Sequential([hub.KerasLayer(module_url)])\n",
    "model.build(input_shape=[None, 160, 160, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MobileNet model to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and preprocess 3 sample ImageNet images\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "bird1 = load_img(\"data/bird1.jpg\", target_size=(160, 160))\n",
    "bird2 = load_img(\"data/bird2.jpg\", target_size=(160, 160))\n",
    "cat1 = load_img(\"data/cat1.jpg\", target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in categories text file\n",
    "\n",
    "with open('data/imagenet_categories.txt') as txt_file:\n",
    "    categories = txt_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function: presents top 5 predictions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_5_predictions(img):\n",
    "    x = img_to_array(img)[np.newaxis, ...] / 255.0\n",
    "    preds = model.predict(x)\n",
    "    top_preds = pd.DataFrame(columns=['prediction'],\n",
    "                             index=np.arange(5)+1)\n",
    "    sorted_index = np.argsort(-preds[0])\n",
    "    for i in range(5):\n",
    "        ith_pred = categories[sorted_index[i]]\n",
    "        top_preds.loc[i+1, 'prediction'] = ith_pred\n",
    "            \n",
    "    return top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 1: bird1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_5_predictions(bird1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 2: bird2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_5_predictions(bird2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 3: cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_5_predictions(cat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python37764bitmyenvconda4a11ba26287d4d1c969b9946e31eb2a2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}